# ğŸ—ï¸ System Architecture

This document describes the complete architecture of the Crystallographic Pattern Generator and Phase Transition system.

---

## Table of Contents

1. [Overview](#1-overview)
2. [Data Pipeline](#2-data-pipeline)
3. [Model Components](#3-model-components)
4. [Training Pipeline](#4-training-pipeline)
5. [Inference Pipeline](#5-inference-pipeline)
6. [File Organization](#6-file-organization)

---

## 1. Overview

The system consists of three main components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HIGH-LEVEL ARCHITECTURE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚   PATTERN    â”‚     â”‚     VAE       â”‚     â”‚   FLOW MATCHING    â”‚    â”‚
â”‚   â”‚   GENERATOR  â”‚â”€â”€â”€â”€â–¶â”‚   (Encoder/   â”‚â”€â”€â”€â”€â–¶â”‚   (Transition      â”‚    â”‚
â”‚   â”‚              â”‚     â”‚    Decoder)   â”‚     â”‚    Learning)       â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â”‚   â–¸ Generates the 17   â–¸ Learns latent      â–¸ Learns continuous       â”‚
â”‚     wallpaper groups     representations      transformations          â”‚
â”‚   â–¸ RGB 256Ã—256        â–¸ 64-dimensional     â–¸ Between any two         â”‚
â”‚   â–¸ Mathematically     â–¸ Clustered by         symmetry groups         â”‚
â”‚     correct symmetry     symmetry group                                 â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Data Pipeline

### 2.1 Pattern Generation

The `WallpaperGroupGenerator` creates mathematically correct patterns for all 17 groups:

```python
# src/dataset/pattern_generator.py

generator = WallpaperGroupGenerator(resolution=256, seed=42)

# Each group uses specific symmetry operations:
# - p1: Only translations
# - p2: 180Â° rotation centers
# - p4m: 90Â° rotation + 4 mirror axes
# - p6m: 60Â° rotation + 6 mirror axes
# etc.

pattern = generator.generate("p6m", motif_size=64, complexity=4)
```

### 2.2 Dataset Structure

The HDF5 dataset format:

```
crystallographic_patterns_colored.h5
â”œâ”€â”€ patterns: (8500, 256, 256, 3)  # RGB images, float64 [0,1]
â”œâ”€â”€ labels: (8500,)                 # Group indices 0-16
â”œâ”€â”€ group_names: (17,)              # ['p1', 'p2', ..., 'p6m']
â””â”€â”€ metadata/
    â”œâ”€â”€ complexity: (8500,)
    â”œâ”€â”€ motif_size: (8500,)
    â””â”€â”€ motif_type: (8500,)

splits.npz
â”œâ”€â”€ train: (5950,)   # 70%
â”œâ”€â”€ val: (1275,)     # 15%
â””â”€â”€ test: (1275,)    # 15%
```

### 2.3 Transition Dataset

For Flow Matching training, we create transition pairs:

```python
# src/dataset/transition_dataset.py

class TransitionDataset(Dataset):
    """
    Creates (z_source, z_target, source_idx, target_idx) pairs.
    
    Strategies:
    - Cross-pattern: Different patterns from different groups
    - Same-pattern: Same latent, different target groups
    - Mixed: 50/50 combination (best results)
    """
```

---

## 3. Model Components

### 3.1 RGB VAE

**Purpose**: Learn compact latent representations of crystallographic patterns.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SimpleVAE Architecture                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ENCODER                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Input: (B, 3, 256, 256) RGB                                        â”‚
â”‚      â†“                                                               â”‚
â”‚  Conv2d(3â†’32, k=4, s=2) + BN + LeakyReLU + ResBlock  â†’ (B, 32, 128) â”‚
â”‚      â†“                                                               â”‚
â”‚  Conv2d(32â†’64, k=4, s=2) + BN + LeakyReLU + ResBlock â†’ (B, 64, 64)  â”‚
â”‚      â†“                                                               â”‚
â”‚  Conv2d(64â†’128, k=4, s=2) + BN + LeakyReLU + ResBlock â†’ (B, 128, 32)â”‚
â”‚      â†“                                                               â”‚
â”‚  Conv2d(128â†’256, k=4, s=2) + BN + LeakyReLU + ResBlock â†’ (B, 256, 16)â”‚
â”‚      â†“                                                               â”‚
â”‚  Conv2d(256â†’512, k=4, s=2) + BN + LeakyReLU + ResBlock â†’ (B, 512, 8)â”‚
â”‚      â†“                                                               â”‚
â”‚  Flatten â†’ (B, 32768)                                                â”‚
â”‚      â†“                                                               â”‚
â”‚  â”œâ”€â”€ Linear(32768â†’64) â†’ Î¼ (mean)                                    â”‚
â”‚  â””â”€â”€ Linear(32768â†’64) â†’ log ÏƒÂ² (log variance)                       â”‚
â”‚                                                                      â”‚
â”‚  REPARAMETERIZATION                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  z = Î¼ + Ïƒ Ã— Îµ,  where Îµ ~ N(0, I)                                  â”‚
â”‚                                                                      â”‚
â”‚  DECODER                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Input: z (B, 64)                                                    â”‚
â”‚      â†“                                                               â”‚
â”‚  Linear(64â†’32768) â†’ Reshape â†’ (B, 512, 8, 8)                        â”‚
â”‚      â†“                                                               â”‚
â”‚  ConvT(512â†’256) + BN + LeakyReLU + ResBlock â†’ (B, 256, 16)         â”‚
â”‚      â†“                                                               â”‚
â”‚  ConvT(256â†’128) + BN + LeakyReLU + ResBlock â†’ (B, 128, 32)         â”‚
â”‚      â†“                                                               â”‚
â”‚  ConvT(128â†’64) + BN + LeakyReLU + ResBlock â†’ (B, 64, 64)           â”‚
â”‚      â†“                                                               â”‚
â”‚  ConvT(64â†’32) + BN + LeakyReLU + ResBlock â†’ (B, 32, 128)           â”‚
â”‚      â†“                                                               â”‚
â”‚  ConvT(32â†’3) + Sigmoid â†’ (B, 3, 256, 256)                           â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Loss Function**:
```
L = L_reconstruction + Î² Ã— L_KL

L_reconstruction = MSE(x, xÌ‚)
L_KL = -0.5 Ã— Î£(1 + log ÏƒÂ² - Î¼Â² - ÏƒÂ²)
```

### 3.2 Flow Matching Transition Model

**Purpose**: Learn continuous transformations between symmetry groups.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FlowMatchingTransition Architecture                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  INPUTS                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  z:           (B, 64)   - Current latent position                   â”‚
â”‚  t:           (B,)      - Time in [0, 1]                            â”‚
â”‚  source_idx:  (B,)      - Source group index (0-16)                 â”‚
â”‚  target_idx:  (B,)      - Target group index (0-16)                 â”‚
â”‚                                                                      â”‚
â”‚  EMBEDDINGS                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Time Embed  â”‚  â”‚ Source Embedâ”‚  â”‚ Target Embedâ”‚                 â”‚
â”‚  â”‚ Sinusoidal  â”‚  â”‚ Learnable   â”‚  â”‚ Learnable   â”‚                 â”‚
â”‚  â”‚ â†’ 64 dim    â”‚  â”‚ â†’ 64 dim    â”‚  â”‚ â†’ 64 dim    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                â”‚                â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                          â”‚                                           â”‚
â”‚                          â–¼                                           â”‚
â”‚  CONCATENATION: [z, t_emb, source_emb, target_emb] â†’ (B, 256)       â”‚
â”‚                                                                      â”‚
â”‚  VELOCITY NETWORK                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Linear(256â†’512) + GELU                                             â”‚
â”‚      â†“                                                               â”‚
â”‚  [ResidualBlock + Self-Attention] Ã— 6 layers                        â”‚
â”‚      â†“                                                               â”‚
â”‚  LayerNorm + Linear(512â†’512) + GELU + Linear(512â†’64)               â”‚
â”‚      â†“                                                               â”‚
â”‚  OUTPUT: v(z, t) âˆˆ â„^64 (predicted velocity)                        â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Training (Flow Matching Loss)**:
```python
# Sample random time t ~ Uniform[0, 1]
t = torch.rand(batch_size)

# Linear interpolation (Optimal Transport path)
z_t = (1 - t) * z_source + t * z_target

# Target velocity is constant for linear interpolation
v_target = z_target - z_source

# Predicted velocity
v_pred = model.velocity_net(z_t, t, source_idx, target_idx)

# Loss = MSE between predicted and target velocity
loss = F.mse_loss(v_pred, v_target)
```

**Inference (Euler Integration)**:
```python
def sample_trajectory(z_start, source_idx, target_idx, n_steps=50):
    dt = 1.0 / n_steps
    z = z_start
    trajectory = [z]
    
    for i in range(n_steps - 1):
        t = i * dt
        v = velocity_net(z, t, source_idx, target_idx)
        z = z + v * dt
        trajectory.append(z)
    
    return trajectory  # [n_steps, batch, latent_dim]
```

### 3.3 Group Embeddings

Each of the 17 groups gets a learnable 64-dimensional embedding, initialized with geometric properties:

```python
# Initialization based on group properties
embedding[i, 0] = rotation_order / 6.0           # Normalized rotation
embedding[i, 1] = sin(2Ï€ Ã— rotation_order / 6)   # Periodic encoding
embedding[i, 2] = cos(2Ï€ Ã— rotation_order / 6)
embedding[i, 3] = lattice_type / 3.0             # 0=oblique, 1=rect, 2=square, 3=hex
embedding[i, 4] = 1.0 if has_reflection else 0.0
embedding[i, 5] = 1.0 if has_glide else 0.0
embedding[i, 6:] = random_init(0, 0.1)           # Learned during training
```

---

## 4. Training Pipeline

### 4.1 Two-Phase Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1: Train VAE (~100 epochs)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Objective: Learn latent representations for all 17 groups          â”‚
â”‚                                                                     â”‚
â”‚  Loss = L_reconstruction + Î² Ã— L_KL                                â”‚
â”‚                                                                     â”‚
â”‚  Î² schedule: 0.0001 â†’ 0.001 (gradually increase KL weight)         â”‚
â”‚                                                                     â”‚
â”‚  Output: checkpoints/vae_checkpoint.pt                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PHASE 2: Train Flow Matching (~100 epochs)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Prerequisites: Trained VAE (frozen during training)                â”‚
â”‚                                                                     â”‚
â”‚  1. Precompute all latent representations z = VAE.encode(pattern)  â”‚
â”‚  2. Create transition pairs (z_source, z_target)                   â”‚
â”‚  3. Train velocity network with Flow Matching loss                  â”‚
â”‚                                                                     â”‚
â”‚  Loss = ||v_pred(z_t, t) - v_target||Â²                             â”‚
â”‚                                                                     â”‚
â”‚  Output: checkpoints/flow_matching_checkpoint.pt                    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Hyperparameters

```python
# VAE Training
VAE_CONFIG = {
    'epochs': 100,
    'batch_size': 32,
    'lr': 1e-4,
    'beta': 0.001,           # KL weight
    'latent_dim': 64,
    'optimizer': 'AdamW',
    'weight_decay': 1e-5,
    'scheduler': 'CosineAnnealing',
}

# Flow Matching Training
FLOW_CONFIG = {
    'epochs': 100,
    'batch_size': 128,
    'lr': 1e-4,
    'hidden_dim': 512,
    'num_layers': 6,
    'embedding_dim': 64,
    'pairs_per_epoch': 20000,
    'optimizer': 'AdamW',
    'weight_decay': 1e-4,
    'scheduler': 'CosineAnnealing',
    'use_amp': True,         # Mixed precision training
}
```

---

## 5. Inference Pipeline

### 5.1 Generate Transition

```python
# 1. Load models
vae = load_vae("checkpoints/vae.pt")
flow = load_flow_matching("checkpoints/flow.pt")

# 2. Encode source pattern
source_pattern = load_pattern("p4m_example.png")
z_source = vae.encode(source_pattern)

# 3. Generate trajectory
trajectory = flow.sample_trajectory(
    z_start=z_source,
    source_idx=GROUP_TO_IDX["p4m"],
    target_idx=GROUP_TO_IDX["p6m"],
    n_steps=60
)

# 4. Decode each frame
frames = [vae.decode(z) for z in trajectory]

# 5. Create animation
create_gif(frames, "p4m_to_p6m.gif", fps=5)
```

### 5.2 Visualization Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      VISUALIZATION OUTPUTS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Every N epochs during training:                                     â”‚
â”‚                                                                      â”‚
â”‚  â”œâ”€â”€ Latent Space                                                    â”‚
â”‚  â”‚   â””â”€â”€ UMAP/PCA projection with all 17 groups color-coded        â”‚
â”‚  â”‚                                                                   â”‚
â”‚  â”œâ”€â”€ Reconstructions                                                 â”‚
â”‚  â”‚   â””â”€â”€ Grid: Original â†’ Reconstructed for each group              â”‚
â”‚  â”‚                                                                   â”‚
â”‚  â”œâ”€â”€ Transition Strips                                               â”‚
â”‚  â”‚   â””â”€â”€ 12-frame horizontal strips showing evolution               â”‚
â”‚  â”‚                                                                   â”‚
â”‚  â”œâ”€â”€ Transition GIFs                                                 â”‚
â”‚  â”‚   â””â”€â”€ 60-frame animated transitions at 5 FPS                     â”‚
â”‚  â”‚                                                                   â”‚
â”‚  â””â”€â”€ Training Curves                                                 â”‚
â”‚      â””â”€â”€ Loss, learning rate, etc. over epochs                      â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. File Organization

```
src/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pattern_generator.py      # WallpaperGroupGenerator
â”‚   â”œâ”€â”€ color_patterns.py         # ColorSchemeGenerator
â”‚   â”œâ”€â”€ dataset.py                # CrystallographicDataset
â”‚   â”œâ”€â”€ dataset_colored.py        # ColoredPatternDataset
â”‚   â”œâ”€â”€ transition_dataset.py     # TransitionDataset, H5PatternDataset
â”‚   â””â”€â”€ turing_patterns.py        # Turing pattern generation
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vae_simple_rgb.py         # SimpleVAE, SimpleVAEConfig
â”‚   â”œâ”€â”€ flow_matching_transition.py  # FlowMatchingTransition
â”‚   â”œâ”€â”€ neural_ode_transition.py  # NeuralODETransition (alternative)
â”‚   â”œâ”€â”€ vae.py                    # Legacy VAE
â”‚   â””â”€â”€ trainer.py                # Training utilities
â”‚
â”œâ”€â”€ visualization/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ visualize.py              # Pattern plotting
â”‚   â”œâ”€â”€ latent_explorer.py        # Latent space visualization
â”‚   â””â”€â”€ training_logger.py        # Training progress logging
â”‚
â””â”€â”€ analysis/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ symmetry_verifier.py      # Verify symmetry correctness
```

---

## Summary

This architecture enables:

1. **Mathematically correct** pattern generation for all 17 wallpaper groups
2. **Compact latent representations** via VAE (256Ã—256Ã—3 â†’ 64 dimensions)
3. **Continuous phase transitions** via Flow Matching (any group â†’ any group)
4. **Real-time monitoring** via dashboard with live visualizations

The modular design allows for easy extension to:
- 3D space groups (230 groups)
- Conditional generation
- Other generative architectures

